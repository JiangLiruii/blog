---
layout:       post
title:        "HTTP(hypertext transfer protocol 超文本传输)"
subtitle:     "无线通信"
date:         2018-12-15 12:00:00
author:       "Lorry"
header-mask:  0.3
header-img:   '/img/Fast-Moving-Light-Wallpaper.jpg'
catalog:      true
multilingual: false
tags:
    - web
---

## History

### HTTP 0.9: 单条语句

Tim Berners-Lee 设计了HTTP, 是最初的www的萌芽阶段

- 客户端请求一个单独的ASCII码字符串
- 客户端请求以CRLF结尾
- 服务器响应一个ASCII码流
- 服务端响应一个HTML
- 传输完成后连接终止

比如现在还支持的telnet命令, GET方法进行请求, 没有请求头或其他元数据, 只有HTML, 这是简单得不能再简单的东西.

`$> telnet google.com 80`

HTTP 0.9的特性:
- 客户端服务端, 请求响应的协议
- ASCII协议, 运行在TCP/IP之上
- 通过HTML进行传输
- 每次请求之后关闭连接

### HTTP/1.0 快速增长

91-95年HTML也发展得很快, 出现了一个叫 "网页浏览器" 的软件, 面向消费者的公用网络基础的需求急剧增长

在 Tim Berner-lee的服务器原型之上, 一家名为National Center of Supercomputing Application(NCSA)的团队做出了第一个受欢迎的浏览器 NCSA Mosaic, 在1994年成立了Mosaic Communication 公司, 最后被更名为网景(Netscape), 在1994年12月发展出了网景导航1.0版本

HTTP/1.0的请求长这样:
```
$> telnet website.org 80

Connected to xxx.xxx.xxx.xxx

GET /rfc/rfc1945.txt HTTP/1.0  --*1
User-Agent: CERN-LineMode/2.15 libwww/2.17b3
Accept: */*

HTTP/1.0 200 OK   --*2
Content-Type: text/plain
Content-Length: 137582
Expires: Thu, 01 Dec 1997 16:00:00 GMT
Last-Modified: Wed, 1 May 1996 12:45:26 GMT
Server: Apache 0.84

(plain-text response)
(connection closed)

*1 HTTP版本的请求行, 紧跟着是请求头
*2 相应状态, 紧跟着响应头
```
跟HTTP 0.9相比有如下改变:
- 请求可以有多个独立头字段的新行组成
- 响应对象会有一个相应状态行
- 响应对象有自己的一套独立头字段的新行
- 不仅仅限于hypertext超文本
- 连接在每个请求之后关闭

> 每个请求都需要一个新的TCP连接导致了性能上的瓶颈, **三次握手的慢启动**

## HTTP/1.1 互联网标准

第一个HTTP/1.1标准在1997年发布, 大概就在1.0版本后的6个月时间. 两个半年后, 1999年, 1.1的一些改进和升级被发布

HTTP/1.1 有如下优化
- keepalive
- chuanked encoding transfers
- byte-range 请求
- 更多的caching机制
- 传输编码
- 请求管道化

```
$> telnet website.org 80
Connected to xxx.xxx.xxx.xxx

GET /index.html HTTP/1.1        ---*1
Host: website.org
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4)... (snip)
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Encoding: gzip,deflate,sdch
Accept-Language: en-US,en;q=0.8
Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3
Cookie: __qca=P0-800083390... (snip)

HTTP/1.1 200 OK         ---*2
Server: nginx/1.0.11
Connection: keep-alive
Content-Type: text/html; charset=utf-8
Via: HTTP/1.1 GWA
Date: Wed, 25 Jul 2012 20:23:35 GMT
Expires: Wed, 25 Jul 2012 20:23:35 GMT
Cache-Control: max-age=0, no-cache
Transfer-Encoding: chunked

100             ---*3
<!doctype html>
(snip)

100
(snip)

0           ---*4

GET /favicon.ico HTTP/1.1       ---*5
Host: www.website.org
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4)... (snip)
Accept: */*
Referer: http://website.org/
Connection: close           ---*6
Accept-Encoding: gzip,deflate,sdch
Accept-Language: en-US,en;q=0.8
Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3
Cookie: __qca=P0-800083390... (snip)

HTTP/1.1 200 OK             ---*7
Server: nginx/1.0.11
Content-Type: image/x-icon
Content-Length: 3638
Connection: close
Last-Modified: Thu, 19 Jul 2012 17:51:44 GMT
Cache-Control: max-age=315360000
Accept-Ranges: bytes
Via: HTTP/1.1 GWA
Date: Sat, 21 Jul 2012 21:35:22 GMT
Expires: Thu, 31 Dec 2037 23:55:55 GMT
Etag: W/PSA-GAu26oXbDi

(icon data)
(connection closed)

*1 请求HTML文件, 需要编码格式, 字符集, cookie元数据
*2 原始HTML请求的块(chunked)响应
*3 以ASCII十六进制表示chunk的字节数(256位)
*4 chunk流的结束响应
*5 在同一个TCP连接中请求icon
*6 通知服务器连接不会再被重用
*7 icon响应, 接着关闭连接
```

> HTTP/1.1中的keepalive为默认开启, 如果不想使用需 `Connection: close`的请求头, 在HTTP/1.0中需要使用`Connection: Keep-Alive`

## HTTP/2: 改善传输性能

随着业务的增长, 用户和web开发真越来越需要接近实时的响应传输和更高协议性能要求, 在HTTP/1.1上修修补补已经不能满足要求了, 所以在2012年有了HTTP/2, HTTP/2有更低的延迟和更高的吞吐量, 但是并没有改变高级协议的语法: 所有的请求头, 值, 使用场景都一样.

任何已有的应用都可以不做任何改变的在HTTP/2中传输. 只是服务器会通过HTTP/2进行响应.

虽然最终的HTTP/2协议标准已经完成, 但是依然需要在可预期的未来兼容HTTP/1.1, 大概还要10年左右吧.

## 网络性能优化要点

在前两篇博客中已经谈到了物理层和协议的优化, 包括
- 延迟和带宽对网络性能的影响
- 传输协议(TCP, UDP)对HTTP的限制
- HTTP协议本身的特性和缺点
- 网页应用的趋势和性能需求
- 浏览器限制和优化

### 超文本, 网页和网页应用

- 超文本
  - www(world wide web)的起源
  - 包含一些基本格式和支持超链接的纯文本
- 网页
  - HTML是作为早期的浏览器版本中超文本的扩展, 可以支持更多的媒体资源, 比如图片和audio, 并添加了很多其他的丰富的布局
  - 十分的好看, 但是没有多少交互, 跟一张打印的纸差不多
- 网页应用
  - 加上了JS和DHTML(dynamic)和Ajax的可交互的网页.
  - 使用复杂图形化脚本, stylesheet和标记的新时代

HTTP0.9会话包含单个文档请求, 足够传输超文本(单document, 一个TCP连接,然后便关闭), 优化的空间仅仅在于短live TCP连接的单个HTTP请求.
然后网页的到来使得单document到document + 依赖的资源, HTTP/1.0引入了HTTP 元数据概念(header), HTTP/1.1面向性能优化为首要任务改进了它, 比如定义了caching, keepalive等. 所以多TCP连接可以实现, 性能的关键从document load time 到 page load time(PLT: 浏览器不再转圈的时间, 技术上说就是onload时间触发的时候, 这个时候js, image等依赖的资源都已经加载完毕)
网页应用使用媒体改进了普通网页, markup 定义基本结构, stylesheet定义layout, 脚本构建交互应用的结果并响应用户输入,而且可能会同时修改stylesheet和markup
结论是page load time 逐渐在性能上跟不上了, 因为都是动态的交互网页应用, 而不是静态的网页, 如何衡量加载每一个资源的时间, 现在需要回答下列几个具体的问题:

- 什么是加载过程的里程碑?
- 用户什么时候可以第一次交互
- 什么用户的交互应该被引入
- 每个用户参与交互和转化率是多少

> DOM, CSSOM, 和JS
> ![](/img/Optimize/Browser_processing.svg)
> DOM解析HTML文档, 同时CSSOM(CSS Object Model)构建具体的样式表和资源, 两者共同生成 **渲染树**, 这是浏览器可以呈现布局信息以及显示在屏幕上的时刻
> 但是还有JS, 可以通过同步的写操作(doc.write)阻塞DOM解析, 并且也可以查询任何对象的样式, 所以DOM被js阻塞, js被CSSOM阻塞
> 这是为什么css在头, js在尾的最佳时间的原理, js会阻塞css, 渲染和脚本的执行都会被css阻塞.


### 剖析现代网页应用

通常的网页(2013年的数据):
- 90个请求, 从15个host获取数据, 1311KB被传输
  - HTML: 10个请求, 52KB
  - Image: 55请求, 812KB
  - Javascript: 15请求, 216KB
  - CSS: 5请求, 36KB
  - 其他 5请求, 195KB

现在可能翻番都不止了.

不像桌面应用, web应用不需要安装, 输入URL, 点击Enter, 就可以运行, 但是桌面应用只需要付出一次安装成本, 但是网页应用需要每次访问都进行一次"安装"--资源下载, DOM和CSSOM的构建, JS的执行. 

#### 速度, 性能和人的接收程度
速度和性能是相对的概念, 每个应用基于商业标准, 应用场景, 用户期望, 任务的复杂度等因素有自己的一套需求.下表是用户的感知与延迟长短的关系

|Delay	|User perception|
|---|---|
|0–100 ms	|Instant|
|100–300 ms	|Small perceptible delay|
|300–1000 ms	|Machine is working|
|1,000+ ms	|Likely mental context switch|
|10,000+ ms	|Task is abandoned|

> 250ms内渲染出页面, 或者只好提供视觉反馈是让人觉得好的网页性能的非官方标准

但是DNS查找, 接下来的TCP握手, TLS的建立, 典型网页请求的几个来回, 很容易就超过100-1000的预算, 所以移动或者说无线网络对快速网页性能有极大的需求.

> 性能越快, PV越高, 钞票越多.

#### 分析数据瀑布

数据瀑布是诊断网络性能的工具, 每个浏览器都提供了查看的方法, 也有一些在线的工具, 比如WebPageTest(此工具需翻墙).

![](/img/Optimize/waterfall.png)

yahoo主页消耗了683ms去下载, 超过200ms都是等待网络, 也就是30%, 然后请求了一大堆的资源, 看下图, 一共52个, 超过30个不同的逐渐, 添加了486KB

![](/img/Optimize/request_resource.png)

要注意,在获取www.yahoo.com的document的时候, 新的HTTP请求也被发出 HTML解析是渐进式的, 允许浏览器尽早的发现需要的资源, 并且并行的发出必要的请求.注意绿色的那根线, 表示 "start render", 这时候所有的资源还没有完全加载, 允许页面边加载, 用户也可以进行交互. 实际上, "Document Complete"事件在蓝色的那根线时触发, 也在剩余资源被加载前.换句话说, 浏览器已经不转圈了, 用户可以继续任务, 但是仍然逐渐的在后台增加新的内容. 比如广告和社交部件.

性能优化不仅仅是前端, 仔细看上图可以看蓝色部分为下载的数据, 绿色部分为TCP握手部分和DNS查找以及等待接收响应的第一个数据的其他网络延迟, 显然蓝色占的比例并不算大, 所以如何减少绿色的部分是后端需要考虑的部分.

最后检查带宽利用率, 可以看到是突发的短时的, 利用率非常的低.这也可以看出带宽不再是大多数网页应用的限制因素, 而是之前一直所说的往返于客户端和服务器之间的延迟

#### 性能来源: 计算, 渲染和网络

网页程序主要包括三个任务
1. 获取数据
2. 页面布局和渲染
3. JS执行

渲染和脚本是单线程的, 交叉执行的model, 不能并发修改正在生成的DOM. 就算优化了JS的执行和渲染, 如果浏览器因网络阻塞也会前功尽弃, 所以迅速获取到网络资源是第一优先级.

##### 更多的带宽并不那么重要
带宽重要, 但是没那么重要, 毕竟每一个ISP和移动运营商一直提醒着高带宽的好处: 更快的上传和下载. 接入更高的带宽固然是好事, 特别时在大量数据传输的时候, 比如video和audio streaming, 但是发生在每天的网页浏览上, 我们是需要成百上千相对小的资源, 向数十个主机请求, 来回的延迟才是限制因素

- yahoo网站中的HD 视频流的限制因素是带宽
- 加载yahoo主页的限制因素是延迟

那为什么处理那么大流量的视频和音频流时都hold得住(现在各种小视频风靡中国), 但是小而短的连接却成了难题呢?

##### 延迟时性能的瓶颈
已经在之前的章节说了很多次为什么延迟时当今每个网页浏览器的限制因素.

![](/img/Optimize/page_load_time_latency_vs_bandwidth.svg)

带宽在4Mbps之后基本上加载事件就保持不变了, 但是延迟是一直减少的

> 移动网络的延迟比有线更高, 所以对移动网络的延迟优化更加至关重要.

#### 人造和真实用户性能衡量

如果可衡量, 那么就可以优化.

通常来说人造数据是在一定的可控制的测量环境下生成的. 每个测试可对应不同的部分, 比如应用服务器吞吐量, 数据库性能, DNS时间等, 然后提供一个基准线帮助检测系统的某个组件性能.

但是人造数据是不足够定位所有的性能瓶颈, 特别是有很多外在条件共同作用决定用户最终体验的场景下.
- 场景和页面选择: 完全复制用户的导航模式是很难的
- 浏览器缓存: 性能很大成都上会基于用户缓存状态
- 中间件: 性能会因为基于中间代理或缓存而大有不同
- 硬件区别: CPU, GPU, 内存性能
- 浏览器区别: 不同种类的浏览器, 相同浏览器的不同版本
- 可连接性: 真实连接中不断改变的带宽和延迟

W3C制定了一个数据聚合处理的Navigation Timming API

![](/img/Optimize/Navigation_API.svg)

这些API暴露了以前无法获取到的数据, 比如通过标准化的 **performance.timing**(可在任意浏览器中打印该数据) 对象获取DNS和TCP连接次数(更高精度, 精确到毫秒). 通过获取该数据, 可以观察真实世界的应用性能.

```js
function init() {
  // 储存相关任务的时间戳
  performance.mark("startTask1"); 
  // 执行应用代码
  applicationCode1();
  performance.mark("endTask1");

  logPerformance();
}

function logPerformance() {
  var perfEntries = performance.getEntriesByType("mark");
  // 循环打印用户timing数据
  for (var i = 0; i < perfEntries.length; i++) { 
    console.log("Name: " + perfEntries[i].name +
                " Entry Type: " + perfEntries[i].entryType +
                " Start Time: " + perfEntries[i].startTime +
                " Duration: "   + perfEntries[i].duration  + "\n");
  }
  // 打印Navigation Timing 对象
  console.log(performance.timing); 
}
```

#### 浏览器优化
浏览器的远远不止一个网络套接字那么简单, 浏览器变得越来越智能:提前解析DNS查找, 提前连接可能的终点, 提前获取并且按资源的优先级排序等. 以下两类是核心优化点

- Document-aware optimization 文档感知优化
  - 熟悉网络协议, 了解document, css和JavaScript解析管道
  - 尽早关键资源,使页面尽早可以达到交互状态
  - 都是通过资源优先级分配, 提前解析或者类似的技术
- 推测行优化
  - 学习用户导航模式, 推测用户可能的动作
  - 提前解析DNS, 提前连接可能的主机名

有四种技术被应用在主流的浏览器上
- 资源提前获取并并排列优先级
- DNS 提前解析
- TCP提前连接
- 页面提前渲染

> 具体可参见 [谷歌浏览器的优化](https://hpbn.co/chrome-networking)

如何利用好这些browser的优化特性?
- 关键资源比如css和js应尽早出现在文档中
- css应该尽早被传输, 因为会阻塞js执行
- 非关键js应该被延后, 以免阻塞DOM和CSSOM
- HTML文档是逐渐被解析的, 所有文档应该间歇发送以获得最佳性能

```html
<!-- 提前解析hostname -->
<link rel="dns-prefetch" href="//hostname_to_resolve.com"> 
<!-- 提前获取关键资源 -->
<link rel="subresource"  href="/javascript/myapp.js"> 
<!-- 提前获取现在或将来导航的资源 -->
<link rel="prefetch"     href="/images/big.jpeg"> 
<!-- 提前渲染具体的页面在用户的下一个目的地 -->
<link rel="prerender"    href="//example.org/next_page.html"> 
```
对大多数用户甚至网页开发者来说, DNS, TCP和SSL延迟是完全透明的, 都是在网络层被协商的, 但是每一步都关乎用户体验, 通过帮助浏览器预期这些往返延时, 能够移除掉这些瓶颈, 是传输更快. 





