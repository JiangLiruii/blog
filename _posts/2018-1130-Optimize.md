---
layout:       post
title:        "WPO(Web Performance Optimization)"
subtitle:     "天下武功, 唯快不破"
date:         2018-11-26 12:00:00
author:       "Lorry"
header-mask:  0.3
header-img:   '/img/Fast-Moving-Light-Wallpaper.jpg'
catalog:      true
multilingual: false
tags:
    - web
---

一直以来不敢写性能优化的东西, 但是自己写的代码越多, 调试的过程越多, 就越来越觉得性能优化是一个值得花大心思去考虑的, 加上自己也一直在致力写出更好的用户体验的代码, 总之, 先开始写吧, 一次写不完就以后分多次进行补充.

其实之前也有说过一些性能优化的东西, 比如介绍 [PWA](./2018-09-03-PWA.md) 的时候, 就有涉及部分的优化方式, 使用SW并发请求啦, 离线缓存资源啦, 还有之前说的HTTP/2的多路复用进行请求啦, 这些都是提升web性能的方面.

# 速度是关键

1. 延迟: 分组从信息源发送到目的地所需的时间
2. 带宽: 逻辑或物理的通信路径最大吞吐量

![](/img/Optimize/1.1.svg)

延迟是以下4种延迟类型的和:

1. Propagation delay(传播延迟) =  传播距离/传播速度
2. Transmission delay(传输延迟) = function(消息长度, 链路速率(bps))
3. Processing delay(处理延迟): 处理包头(packet header), 检查位(bit-level)错误, 并且决定包的目的地花的时间.
4. Queuing delay(排队延迟): 包排队等待处理的时间

传输延迟通常是一个不可变的, 因为传输的媒介都一样, 速度也都大致相等, 接近光速. 但是传输延迟就不一样了, 比如10Mb的文件, 1Mbps的带宽需要10s, 而100Mbps的带宽就只需要0.1s就可以传上去了.**注意Bps(bytes per second)和bps(bits per second)的区别**
当文件传入路由器之后, 会检查包头去决定出口路由, 并且会检查数据. 但这些都是硬件层面的, 处理延迟很小, 不过也不代表不存在.最后如果包发得过快, 路由去需要一个buffer来排队这些包, 这就是排队延迟.

每个数据包的发送都会在每个延迟上面产生很多次.

通常来说300ms用户可以感知到有点卡顿, 1000ms也就是1s用户就能感受到"等待".所以, **必须在每个开发阶段设立明确的标准, 将延迟控制在某个范围内, 但永远也不可能消除延迟.**



# TCP的构成
因特网有两个核心, **IP 和 TCP**, TCP是负责在不可靠传输信道上进行可靠传输的抽象层, 向在它之上的应用层隐藏了大多数网络通信的复杂细节. 采用TCP可以保证发送的所有字节都能完整的被接受, 而且到达客户端的顺序也一样. 但是付出的代价就是时间控制不够好, 这也为之后进行web性能优化提出了挑战.

## 最著名的三次握手
实际上我认为三次握手这个说法容易有误会, 因为握手都是需要双方见面进行交流的英文原文叫 **Three-Way Handshake**, 跟次数好像没有关系, 仅仅是指三种不同的握手方法

1. SYN x=rand()
2. SYN + ACK x+1 y=rand()
3. ACK x+1 y+1 + 应用数据

![](/img/Optimize/handshake.svg)

注意, 在第三个方法种的应用数据是一定要在发送完ACK之后才能发送, 因为服务器只有在接收到ACK之后才会接受应用数据.

每一个TCP建立都需要这个过程, 代价很大, 所以提高TCP性能的关键在于重用连接.

## 拥塞预防及控制

拥塞控制是因为IP与TCP 即传输层与数据报层之间的交互会导致拥塞, 如果往返的时间超过了所有主机的最大间隔, 那么相应的主机会在网络种制造越来越多的数据报副本. 最终所有的缓冲区都将被填满, 多出来的分组将会被删掉,

### 流量控制:预防发送端过多发送数据到接收端的机制

TCP每一方都需要生命自己的接收窗口 rwnd(recieve window)

![](/img/Optimize/rwnd.svg)

当下载数据时, 浏览器rwnd可能成为性能瓶颈, 但是当上传数据时, 服务器的窗口可能成为性能瓶颈. 所以当接收的一端跟不上发送的数据时, 需要向发送端发送一个较小的rwnd.

该过程持续整个生命周期, 每个ACK分组都会携带相应的最新rwnd.

#### 窗口缩放: TCP的rwnd字段时16位, 最大也只能到2^16次方, 不能获得最优性能. 窗口缩放可以将2^16字节提高到1G字节(2^30), 是在三次握手时设置的, 某一个值表示将来将ACK左移16位窗口字节的位数.

### 慢启动
流量控制可以防止发送端不过多的向接收端过多的发送数据, 但没有机制预防任何一端向潜在网络过多发送数据. 因为在网络建立之初, 谁也不知道双方发可用带宽是多少, 而且就算知道了, 带宽也会动态的变化, 比如你在看电影, 忽然你同学也打开了看电影的网址, 这样你的可用带宽就几乎减少了一半, 那么按照之前带宽发送过来的数据对于接收方来说就太多了.那么就会在网关处堆积, 超过缓冲便会删除分组降低传输效率.

之前说了TCP在三次握手时会交换rwnd, 而服务器在握手之初会初始化一个保守的**拥塞窗口(cwnd)**,表示发送端从客户端确认ACK之前可以发送的数据量限制.

发送端不会发送cwnd, 服务器只是维护这样一个变量, 收发双方可以发送的传输数据量(未经ACK确认的)为min(rwnd, cwnd), 在每收到一个ACK, cwnd就按2的指数倍增长.直到某个值的时候发现有丢包了, 那么就减半,再按照之前的指数增长规律增长.

![](/img/Optimize/congestion&#32;control.svg)

0 --> 10 --> 20 --> 40 --> 80 --> 160 --> 80 --> **80 + 10 --> 90 + 10 --> 100 + 20 --> 120 + 40** 一定注意后面的变化规律.

cwnd到达N所需要的时间为:(initial cwnd通常为10(之前为4))

![](/img/Optimize/cwnd_formula.svg)

之前说了,传输数据量的大小时cwnd与rwnd的最小值, 假设rwnd的值为64KB, RTT(往返时间)为56ms(伦敦到纽约), N = 64 * 2^10 / 1460(每段TCP的大小) = 45, 带入公式得168ms.

要想提高cwnd的增长率, 有两个方法:

1. 缩短收发两地的距离, 这样往返时间会缩短
2. 提高初始cwnd到10segments, (之前都是4segment, 现在基本上已经都支持10了)

对大型数据的下载慢启动不算是大问题因为会在几百毫秒之内就到达最大cwnd, 比如下载一个歌曲可能需要几十秒, 那么毫秒级的慢启动的影响就要小得多. 但是往往还有很多是小数据请求, 比如一个json, css, 可能也就几kb, 所以可能经常在还没有达到最大cwnd的时候就已经传输完成了, 无法最大化的利用TCP的传输优势. 换句话说, 收发两地的距离对于小文件的传输吞吐量至关重要.

#### SSR(slow-start restart)慢启动重启

在TCP被闲置一段时间后(keep-alive的长周期TCP连接), cwnd会被重置到初始值, 这是因为下次再活跃连接的时候, 网络状况可能已经发生了改变, 为了避免拥塞, 所以会重置, 但是这种情况较小, 可以对其进行禁用:(LINUX)

> - $> sysctl net.ipv4.tcp_slow_start_after_idle
> - $> sysctl -w net.ipv4.tcp_slow_start_after_idle=0

举个例子:

![](/img/Optimize/cwnd_example.svg)

一个全新的TCP建立并传输一个64KB的文件需要264ms, 如果这个TCP连接可以复用呢?就只需要一个往返就够了, 可以用最大窗口进行传输.

![](/img/Optimize/multi_cwnd.svg)

可以看到, 带宽再也不是影响因素, 延迟和拥塞窗口大小成为了限制原因.现在已经有很多可以优化TCP拥塞控制重用连接:
- keepalive
- pipelining
- multiplexing



## 带宽延迟积(BDP bandwidth delay product)
之前说了在达到最大的cwnd之前每次发生的数据都会比前一次指数增大, 在这种情况下, 必须停下来等待这个比前一次更大的数据被确认(因为不知道是否发生丢包), 需要等待多久? 往返时间.
这个延迟积就是 数据链路的容量 * 端到端的延迟(往返时间), 这个结果就是任意时刻处在途中未确认状态的最大数据量

![](/img/Optimize/data_gap.svg)

假设发送端带宽10Mbit/s, 接收端100Mbit/s+, 往返时间100ms, 那么cwnd和rwnd的最小值应该设置为多少?
> 10Mbit/s = 10000000 / (8* 1024)= 1221KB/s
> 1221*0.1 = 122.1KB
之前说过最大的只能到64KB, 所以需要窗口缩放.

## HOLB(head-of-line blocking)
先看看TCP已经说过的优点吧, 这些优点使TCP成为最流行的应用传输方式
- 在不可靠通道的可靠传输
    - 包错误检测和纠正
    - 顺序传输
    - 丢包重发
    - 流控制
    - 拥塞控制
    - 拥塞预防
因为TCP会为每一个packet唯一命名并指定顺序, 如果有一个包丢失, 那么接收端会一直等待直到这个丢失的包重新到达接收端之后才会接收其他的packet, 这样就导致了线头阻塞(HOLB), 而应用时在TCP层之上的, 不知道这些具体的情况, 只能直到--哦? 有延迟?
因为这样的有序性, 所以在应用层代码中是不需要考虑数据排序的, 只要接收到数据就一定有序. 但是这是以packet到达的时间而有不可预料的延迟, 导致网络抖动.负面影响应用层的性能

![](img/HOL_blocking.png)

有的传输并不需要TCP的所有特性, 比如顺序传输和丢包重发在某些传输里面是可以容忍的. 比如每个packet都是独立的, 并不相互依赖, 顺序也就不重要了, 并且如果每个packet都会覆盖上一个packet, 那么丢包重发也不重要了(实际上丢包是影响TCP的最大因素), 应用场景为: 视频, 游戏, 音频.遗憾的是TCP没有可配置的选项, 所以WebRTC使用UDP的原因.

## TCP的优化
TCP对所有网络节点一视同仁, 具有自适应和最大限度利用底层网络的协议, 优化的最佳途径便是优化阻塞算法, 调整感知当前网络的感知方式等.
总结下TCP的关键点:
- 三次握手
- 慢启动
- 流和阻塞控制吞吐量
- 当前阻塞窗口控制吞吐量

影响延迟的关键就是缩短接收者和发送者两者的距离, 尽管现在带宽的不断提升, 但延迟受限于传播的速度(折射率已经到1.5, 很难再提高了), TCP的瓶颈都是延迟.

### 服务器配置调优

更新主机内核系统(往往需要升级后的代码修改)
- 窗口缩放, 增大最大接收窗口大小
- 增大TCP的初始阻塞窗口--initial cwnd
- 禁用空闲时的慢启动重启
- TCP快速打开 -- TFO

### 应用程序行为调优
- 发送数据越少越好
    - 减少下载不必要的资源
    - 压缩算法(gzip)
- 不能让传输速度更快, 但是可以让传输距离更短
    - 部署CDN
- TCP重用
    - 避免慢启动和阻塞控制影响

### 性能检查清单
其实就是把上述的优化整理到一起:

- 服务器内核升级为最新版本
- cwnd设置为10
- 打开窗口缩放
- 阻止空闲后的慢启动
- 尽可能的使用TFO(需服务器和客户端都支持)
- 避免冗余数据传输
- 压缩传输数据
- 缩短传输距离
- 尽可能重用TCP




### TCP 快速打开 
TFO(TCP fast open) 是可以减少一次握手的

