---
layout:       post
title:        "WPO(Web Performance Optimization)"
subtitle:     "天下武功, 唯快不破"
date:         2018-11-26 12:00:00
author:       "Lorry"
header-mask:  0.3
header-img:   '/img/Fast-Moving-Light-Wallpaper.jpg'
catalog:      true
multilingual: false
tags:
    - web
---

一直以来不敢写性能优化的东西, 但是自己写的代码越多, 调试的过程越多, 就越来越觉得性能优化是一个值得花大心思去考虑的, 加上自己也一直在致力写出更好的用户体验的代码, 总之, 先开始写吧, 一次写不完就以后分多次进行补充.

其实之前也有说过一些性能优化的东西, 比如介绍 [PWA](./2018-09-03-PWA.md) 的时候, 就有涉及部分的优化方式, 使用SW并发请求啦, 离线缓存资源啦, 还有之前说的HTTP/2的多路复用进行请求啦, 这些都是提升web性能的方面.

# 速度是关键

1. 延迟: 分组从信息源发送到目的地所需的时间
2. 带宽: 逻辑或物理的通信路径最大吞吐量

![](/img/Optimize/1.1.svg)

延迟是以下4种延迟类型的和:

1. Propagation delay(传播延迟) =  传播距离/传播速度
2. Transmission delay(传输延迟) = function(消息长度, 链路速率(bps))
3. Processing delay(处理延迟): 处理包头(packet header), 检查位(bit-level)错误, 并且决定包的目的地花的时间.
4. Queuing delay(排队延迟): 包排队等待处理的时间

传输延迟通常是一个不可变的, 因为传输的媒介都一样, 速度也都大致相等, 接近光速. 但是传输延迟就不一样了, 比如10Mb的文件, 1Mbps的带宽需要10s, 而100Mbps的带宽就只需要0.1s就可以传上去了.**注意Bps(bytes per second)和bps(bits per second)的区别**
当文件传入路由器之后, 会检查包头去决定出口路由, 并且会检查数据. 但这些都是硬件层面的, 处理延迟很小, 不过也不代表不存在.最后如果包发得过快, 路由去需要一个buffer来排队这些包, 这就是排队延迟.

每个数据包的发送都会在每个延迟上面产生很多次.

通常来说300ms用户可以感知到有点卡顿, 1000ms也就是1s用户就能感受到"等待".所以, **必须在每个开发阶段设立明确的标准, 将延迟控制在某个范围内, 但永远也不可能消除延迟.**



# TCP的构成
因特网有两个核心, **IP 和 TCP**, TCP是负责在不可靠传输信道上进行可靠传输的抽象层, 向在它之上的应用层隐藏了大多数网络通信的复杂细节. 采用TCP可以保证发送的所有字节都能完整的被接受, 而且到达客户端的顺序也一样. 但是付出的代价就是时间控制不够好, 这也为之后进行web性能优化提出了挑战.

## 最著名的三次握手
实际上我认为三次握手这个说法容易有误会, 因为握手都是需要双方见面进行交流的英文原文叫 **Three-Way Handshake**, 跟次数好像没有关系, 仅仅是指三种不同的握手方法

1. SYN x=rand()
2. SYN + ACK x+1 y=rand()
3. ACK x+1 y+1 + 应用数据

![](/img/Optimize/handshake.svg)

注意, 在第三个方法种的应用数据是一定要在发送完ACK之后才能发送, 因为服务器只有在接收到ACK之后才会接受应用数据.

每一个TCP建立都需要这个过程, 代价很大, 所以提高TCP性能的关键在于重用连接.

## 拥塞预防及控制

拥塞控制是因为IP与TCP 即传输层与数据报层之间的交互会导致拥塞, 如果往返的时间超过了所有主机的最大间隔, 那么相应的主机会在网络种制造越来越多的数据报副本. 最终所有的缓冲区都将被填满, 多出来的分组将会被删掉,

### 流量控制:预防发送端过多发送数据到接收端的机制

TCP每一方都需要生命自己的接收窗口 rwnd(recieve window)

![](/img/Optimize/rwnd.svg)

当下载数据时, 浏览器rwnd可能成为性能瓶颈, 但是当上传数据时, 服务器的窗口可能成为性能瓶颈. 所以当接收的一端跟不上发送的数据时, 需要向发送端发送一个较小的rwnd.

该过程持续整个生命周期, 每个ACK分组都会携带相应的最新rwnd.

#### 窗口缩放: TCP的rwnd字段时16位, 最大也只能到2^16次方, 不能获得最优性能. 窗口缩放可以将2^16字节提高到1G字节(2^30), 是在三次握手时设置的, 某一个值表示将来将ACK左移16位窗口字节的位数.

### 慢启动
流量控制可以防止发送端不过多的向接收端过多的发送数据, 但没有机制预防任何一端向潜在网络过多发送数据. 因为在网络建立之初, 谁也不知道双方发可用带宽是多少, 而且就算知道了, 带宽也会动态的变化, 比如你在看电影, 忽然你同学也打开了看电影的网址, 这样你的可用带宽就几乎减少了一半, 那么按照之前带宽发送过来的数据对于接收方来说就太多了.那么就会在网关处堆积, 超过缓冲便会删除分组降低传输效率.

之前说了TCP在三次握手时会交换rwnd, 而服务器在握手之初会初始化一个保守的**拥塞窗口(cwnd)**,表示发送端从客户端确认ACK之前可以发送的数据量限制.

发送端不会发送cwnd, 服务器只是维护这样一个变量, 收发双方可以发送的传输数据量(未经ACK确认的)为min(rwnd, cwnd), 在每收到一个ACK, cwnd就按2的指数倍增长.直到某个值的时候发现有丢包了, 那么就减半,再按照之前的指数增长规律增长.

![](/img/Optimize/congestion&#32;control.svg)

0 --> 10 --> 20 --> 40 --> 80 --> 160 --> 80 --> **80 + 10 --> 90 + 10 --> 100 + 20 --> 120 + 40** 一定注意后面的变化规律.

cwnd到达N所需要的时间为:(initial cwnd通常为10(之前为4))

![](/img/Optimize/cwnd_formula.svg)

之前说了,传输数据量的大小时cwnd与rwnd的最小值, 假设rwnd的值为64KB, RTT(往返时间)为56ms(伦敦到纽约), N = 64 * 2^10 / 1460(每段TCP的大小) = 45, 带入公式得168ms.

要想提高cwnd的增长率, 有两个方法:

1. 缩短收发两地的距离, 这样往返时间会缩短
2. 提高初始cwnd到10segments, (之前都是4segment, 现在基本上已经都支持10了)

对大型数据的下载慢启动不算是大问题因为会在几百毫秒之内就到达最大cwnd, 比如下载一个歌曲可能需要几十秒, 那么毫秒级的慢启动的影响就要小得多. 但是往往还有很多是小数据请求, 比如一个json, css, 可能也就几kb, 所以可能经常在还没有达到最大cwnd的时候就已经传输完成了, 无法最大化的利用TCP的传输优势. 换句话说, 收发两地的距离对于小文件的传输吞吐量至关重要.

#### SSR(slow-start restart)慢启动重启

在TCP被闲置一段时间后(keep-alive的长周期TCP连接), cwnd会被重置到初始值, 这是因为下次再活跃连接的时候, 网络状况可能已经发生了改变, 为了避免拥塞, 所以会重置, 但是这种情况较小, 可以对其进行禁用:(LINUX)

> - $> sysctl net.ipv4.tcp_slow_start_after_idle
> - $> sysctl -w net.ipv4.tcp_slow_start_after_idle=0

举个例子:

![](/img/Optimize/cwnd_example.svg)

一个全新的TCP建立并传输一个64KB的文件需要264ms, 如果这个TCP连接可以复用呢?就只需要一个往返就够了, 可以用最大窗口进行传输.

![](/img/Optimize/multi_cwnd.svg)

可以看到, 带宽再也不是影响因素, 延迟和拥塞窗口大小成为了限制原因.现在已经有很多可以优化TCP拥塞控制重用连接:
- keepalive
- pipelining
- multiplexing



## 带宽延迟积(BDP bandwidth delay product)
之前说了在达到最大的cwnd之前每次发生的数据都会比前一次指数增大, 在这种情况下, 必须停下来等待这个比前一次更大的数据被确认(因为不知道是否发生丢包), 需要等待多久? 往返时间.
这个延迟积就是 数据链路的容量 * 端到端的延迟(往返时间), 这个结果就是任意时刻处在途中未确认状态的最大数据量

![](/img/Optimize/data_gap.svg)

假设发送端带宽10Mbit/s, 接收端100Mbit/s+, 往返时间100ms, 那么cwnd和rwnd的最小值应该设置为多少?
> 10Mbit/s = 10000000 / (8* 1024)= 1221KB/s
> 1221*0.1 = 122.1KB
之前说过最大的只能到64KB, 所以需要窗口缩放.

## HOLB(head-of-line blocking)
先看看TCP已经说过的优点吧, 这些优点使TCP成为最流行的应用传输方式
- 在不可靠通道的可靠传输
    - 包错误检测和纠正
    - 顺序传输
    - 丢包重发
    - 流控制
    - 拥塞控制
    - 拥塞预防
因为TCP会为每一个packet唯一命名并指定顺序, 如果有一个包丢失, 那么接收端会一直等待直到这个丢失的包重新到达接收端之后才会接收其他的packet, 这样就导致了线头阻塞(HOLB), 而应用时在TCP层之上的, 不知道这些具体的情况, 只能直到--哦? 有延迟?
因为这样的有序性, 所以在应用层代码中是不需要考虑数据排序的, 只要接收到数据就一定有序. 但是这是以packet到达的时间而有不可预料的延迟, 导致网络抖动.负面影响应用层的性能

![](img/HOL_blocking.png)

有的传输并不需要TCP的所有特性, 比如顺序传输和丢包重发在某些传输里面是可以容忍的. 比如每个packet都是独立的, 并不相互依赖, 顺序也就不重要了, 并且如果每个packet都会覆盖上一个packet, 那么丢包重发也不重要了(实际上丢包是影响TCP的最大因素), 应用场景为: 视频, 游戏, 音频.遗憾的是TCP没有可配置的选项, 所以WebRTC使用UDP的原因.

## TCP的优化
TCP对所有网络节点一视同仁, 具有自适应和最大限度利用底层网络的协议, 优化的最佳途径便是优化阻塞算法, 调整感知当前网络的感知方式等.
总结下TCP的关键点:
- 三次握手
- 慢启动
- 流和阻塞控制吞吐量
- 当前阻塞窗口控制吞吐量

影响延迟的关键就是缩短接收者和发送者两者的距离, 尽管现在带宽的不断提升, 但延迟受限于传播的速度(折射率已经到1.5, 很难再提高了), TCP的瓶颈都是延迟.

### 服务器配置调优

更新主机内核系统(往往需要升级后的代码修改)
- 窗口缩放, 增大最大接收窗口大小
- 增大TCP的初始阻塞窗口--initial cwnd
- 禁用空闲时的慢启动重启
- TCP快速打开 -- TFO

### 应用程序行为调优
- 发送数据越少越好
    - 减少下载不必要的资源
    - 压缩算法(gzip)
- 不能让传输速度更快, 但是可以让传输距离更短
    - 部署CDN
- TCP重用
    - 避免慢启动和阻塞控制影响

### 性能检查清单
其实就是把上述的优化整理到一起:

- 服务器内核升级为最新版本
- cwnd设置为10
- 打开窗口缩放
- 阻止空闲后的慢启动
- 尽可能的使用TFO(需服务器和客户端都支持)
- 避免冗余数据传输
- 压缩传输数据
- 缩短传输距离
- 尽可能重用TCP

# 构建UDP

User Datagram Protocol, 在1980年继TCP/IP之后被加入核心网络协议. UDP可以被成为null协议, 因为简单到可以用一张餐巾纸来写完.

## 数据报
一个子包含, 独立的数据实体, 携带能够从源到目的地节点的路由信息而不依赖之前在节点和传输网之间的交换

注意 datagram和packet的区别, packet表示任意一种格式化的数据块, datagram通常时通过不可靠服务传输packets, 不保证送达, 没有失败提示. 这也是为什么经常会讲UDP中的U 翻译成 **Unreliable**而不是User.

最出名的UDP应用应该要算DNS(Domain Name System)了, 尽管浏览器本身依赖于UDP, 但是UDP协议从来没有被暴露作为一等(first class)传输而给到页面或者应用, 因为绝大多数都是TCP. 直到WebRTC的诞生.

## 无协议服务

要理解为什么UDP时无协议的, 首先了解一下IP, IP在TCP和UDP协议层下面一层, 负责基于地址将数据报从源到目的地主机的传输. 因此, message时包裹在IP包里的(包含源和目的地址和众多的其他路由参数).下图是20bytes的IPv4

![](/img/ipv4_header.svg)

UDP协议再把上面的message封装到它自己的结构里, 包含4个额外的字段
- 源端口(可选)
- 目的端口
- 包长度
- checksum(校验和, 可选)

因此, 当IP传输packet到目的端口时, 主机可以拆封这个UDO包, 检验应用的目的端口, 然后传输message. 完毕了, 没有更多, 也没有更少.以下是8bytes的UDP header

![](/img/UDP_header.svg)

校验和是可选的, 因为IP包里有它自己的校验和. 所以应用能够在UDP之上进行error检测和error纠正, UDP的核心是仅仅通过嵌入源和目的端口, 提供一个 **"应用复用"**IP的功能. 总结以下UDP的无服务特性:

- 不保证message传输: 没有确认, 重发, 超时
- 不保证传输顺序: 没有包序列, 不重新排序, 没有HOLB
- 无连接状态的跟踪: 没有连接建立或关闭的状态机
- 无阻塞控制: 没有内建的客户端或网络反馈机制

TCP是一种面向可以通过多个没有明显限制的packets传输协议的字节流. 所以才需要两端建立一个保证这些包按需不丢失到达, 而UDP的数据报中都有明确的限制, 
- 每个数据报被单个IP包中包裹
- 每个应用yields(生成器式)的读取完整的信息
- 数据报不能被分片

UDP式一个简单的无状态协议, 适合在其他应用协议之上的辅助:实际上协议设计时的所有决定都是由协议上层来决定. 但是在使用自己的协议去替代TCP之前, 需要仔细想想复杂细节, 比如UDP与很多层的中间间打交道(NAT 穿透), 而且需要是一个通用的网络协议. TCP算法和他的状态机经过了几十年的磨合和改进, 并且融入了几十种并不那么容易去模仿的机制.

## UDP和NAT(Network Address Translators:网络地址转换器)

IPv4只有32位长, 所以最多可以提供4.29百万个唯一ip地址. 为了解决地址被耗尽的问题, NAT被作为临时过渡方案, 在边缘网中添加NAT设备以重用IP.NAT 维护一个遍历本地IP和端口元组到一个或多个公网IP和端口元组的表.但是到后来, NAT不再是临时的解决方案, 而是网络中的基础组成部分了.

![](/img/IPNAT.svg)

因为有了NAT, 所以有了各类的IP地址, 下面是保留的私有网络范围:
|IP address range |Number of addresses|
|---|---|
|10.0.0.0–10.255.255.255|16,777,216|
|172.16.0.0–172.31.255.255|1,048,576|
|192.168.0.0–192.168.255.255|65,536|

为了避免路由错误, 公共主机不能被分配保留的私有网络范围IP

### 连接状态 超时

在 NAT 转换中UDP有一个问题是路由表必须维持去传输数据报. NAT 中间件依赖连接状态, 而 UDP 不像 TCP , 没有握手, 也没有连接终止, 没有一个很明确的连接状态可以监视.

所以NAT替UDP维护了一个表, 因为UDP没有关闭的标志, NAT只能设置延迟(Timeouts)来关闭连接, 设置的值是没有标准的, 最佳实践是每次接到一个UDP会刷新对应的时间.

虽然理论上TCP其实用不着设置超时的, 因为TCP有具体的连接状态, 但许多NAT设备都使用了同一种超时逻辑, 所以如果发现某些TCP连接被扔掉, 或许可以想想是不是NAT延时的问题.

### NAT 穿透
刚刚说的不可靠的连接状态是NAT的一个严重issue, 但是在应用UDP的时候还有更大的一个issue.当建立UDP连接时, 特别是P2P应用
- VoIP
- Games
- File Sharing
这些都需要客户端和服务端在peers之间都可以双向通信

但是NAT内网的设备不知道外网的IP,只知道内网IP地址, NAT在负责传输时的重写, 包括
- UDP分组的源端口, 地址
- IP分组的源IP地址

所以如果客户在应用程序中使用内网与外网通信是必然会失败,所以NAT穿透就没有意义了, 除非内网设备必须知道自己的外网IP.

但是知道公网IP还不足以成功传输UDP, 就像之前说的, 任何到达公网IP的NAT设备的packet必须由一个终点端口和一个table可以翻译内部的终点主机的IP和端口元组.如果表的入口不存在, 就比如是某个人想尝试型的连接以下公网, 那么这个包就被丢弃了. NAT设备就像一个简单的包过滤器, 因为它没有办法自动决定内部路由, 除非用户显式地通过端口转发(port-forwarding)或类似的机制配置过.

![](/img/DropNAT.svg)

需要注意的是, 上述问题对客户端来说不是问题, 因为客户端会基于内部网络实现交互并且在过程中建立表的转换记录. 但是在处理有NAT的入站的来自P2P应用连接时, 还是会面对这个问题. 发明了很多穿透技术(TURN, STUN, ICE等), 在客户端和服务端都建立UDP peers之间的端到端连接活动

#### STUN, TURN, ICE

STUN(Session Tranversal Utilities) 可以让主机应用发现当前是否有NAT参与传输, 如果有的话就位当前连接获取公网IP和端口元组. 要完成这个需求 协议需要在公网的第三方STUN服务器的协助.

![](/img/STUN_query.svg)

### TCP 快速打开 
TFO(TCP fast open) 是可以减少一次握手的

